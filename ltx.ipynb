{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cfec73b4-071d-42ed-b997-1ce18cb4de52",
   "metadata": {},
   "source": [
    "ic| media_items.shape: torch.Size([1, 3, 1, 512, 768])\n",
    "ic| num_conds: 3\n",
    "ic| prompt_embeds.shape: torch.Size([1, 128, 4096])\n",
    "    prompt_attention_mask.shape: torch.Size([1, 128])\n",
    "    negative_prompt_embeds.shape: torch.Size([1, 128, 4096])\n",
    "    negative_prompt_attention_mask.shape: torch.Size([1, 128])\n",
    "ic| '----stg--------'\n",
    "ic| prompt_embeds_batch.shape: torch.Size([3, 128, 4096])\n",
    "ic| conditioning_method: <ConditioningMethod.FIRST_FRAME: 'first_frame'>\n",
    "ic| vae_per_channel_normalize: True\n",
    "ic| image_cond_noise_scale: 0.15\n",
    "ic| init_latents.shape: torch.Size([1, 6144, 128])\n",
    "ic| conditioning_mask.shape: torch.Size([1, 6144])\n",
    "\n",
    "1,3,49,512,768 --> 1, 128, 7, 16, 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6057e18-8eee-4ed8-ac1e-189953f16722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "from datetime import timedelta\n",
    "import argparse\n",
    "import json\n",
    "# ----------------------------------------------------\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from yaml import load, dump, Loader, Dumper\n",
    "# ----------------------------------------------------\n",
    "import diffusers\n",
    "import transformers\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.training_utils import (\n",
    "    cast_training_params,\n",
    "    compute_density_for_timestep_sampling,\n",
    "    compute_loss_weighting_for_sd3,\n",
    ")\n",
    "from diffusers.models.autoencoders.vae import DiagonalGaussianDistribution\n",
    "from diffusers.utils import export_to_video, load_image, load_video\n",
    "from peft import LoraConfig, get_peft_model_state_dict, set_peft_model_state_dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import (\n",
    "    DistributedDataParallelKwargs,\n",
    "    InitProcessGroupKwargs,\n",
    "    ProjectConfiguration,\n",
    "    set_seed,\n",
    "    gather_object,\n",
    ")\n",
    "# ----------------------------------------------------\n",
    "from dataset import BucketSampler, PrecomputedDataset\n",
    "from ltx_video_lora import *\n",
    "# ----------------------------------------------------\n",
    "from utils.file_utils import find_files, delete_files, string_to_filename\n",
    "from utils.optimizer_utils import get_optimizer, gradient_norm\n",
    "from utils.memory_utils import get_memory_statistics, free_memory, make_contiguous\n",
    "from utils.torch_utils import unwrap_model, align_device_and_dtype\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "244d52dd-e693-4c00-9073-97839dc80231",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_LEVEL = \"DEBUG\"\n",
    "logger = get_logger(\"ltxtrainer\")\n",
    "logger.setLevel(LOG_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53281b47-d253-4e29-946a-6f9ca84ae712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    # Training state\n",
    "    seed: int = None\n",
    "    model_name: str = None\n",
    "    accelerator: Accelerator = None\n",
    "    weight_dtype: torch.dtype = None\n",
    "    train_epochs: int = None\n",
    "    train_steps: int = None\n",
    "    overwrote_max_train_steps: bool = False\n",
    "    num_trainable_parameters: int = 0\n",
    "    learning_rate: float = None\n",
    "    train_batch_size: int = None\n",
    "    generator: torch.Generator = None\n",
    "\n",
    "    # Hub state\n",
    "    repo_id: str = None\n",
    "    # Artifacts state\n",
    "    output_dir: str = None\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config_file) -> None:\n",
    "        cd = load(open(config_file, \"r\"), Loader=Loader)\n",
    "        cd.setdefault(\"train_steps\", None)\n",
    "        cd.setdefault(\"logging_dir\", \"logs\")\n",
    "        cd.setdefault(\"report_to\", \"none\")\n",
    "        cd.setdefault(\"dataset_file\", None)\n",
    "        cd.setdefault(\"pin_memory\", True)\n",
    "        cd.setdefault(\"allow_tf32\", True)\n",
    "        cd.setdefault(\"scale_lr\", True)\n",
    "        cd.setdefault(\"train_type\", \"lora\") # or full\n",
    "        cd.setdefault(\"optimizer_8bit\", True)\n",
    "        cd.setdefault(\"optimizer_torchao\", False)\n",
    "        cd.setdefault(\"caption_dropout_technique\", \"zero\")\n",
    "        # ----------------- optimizer params --------\n",
    "        cd.setdefault(\"optimizer\" \"adamw\")\n",
    "        cd.setdefault(\"lr\", float(1e-4))\n",
    "        cd.setdefault(\"scale_lr\",  False)\n",
    "        cd.setdefault(\"lr_scheduler\", \"constant_with_warmup\")\n",
    "        cd.setdefault(\"lr_warmup_steps\", 1000)\n",
    "        cd.setdefault(\"lr_num_cycles\", 1)\n",
    "        cd.setdefault(\"lr_power\",  1.0)\n",
    "        cd.setdefault(\"beta1\",  0.9)\n",
    "        cd.setdefault(\"beta2\",  0.95)\n",
    "        cd.setdefault(\"beta3\",  0.999)\n",
    "        cd.setdefault(\"weight_decay\",  0.0001)\n",
    "        cd.setdefault(\"epsilon\",  float(1e-8))\n",
    "        cd.setdefault(\"max_grad_norm\",  1.0)\n",
    "        # ---------------- Diffusion arguments\n",
    "        cd.setdefault(\"flow_resolution_shifting\", False)\n",
    "        cd.setdefault(\"flow_base_image_seq_len\", 256)\n",
    "        cd.setdefault(\"flow_max_image_seq_len\", 4096)\n",
    "        cd.setdefault(\"flow_base_shift\", 0.5)\n",
    "        cd.setdefault(\"flow_max_shift\", 1.15)\n",
    "        cd.setdefault(\"flow_shift\", 1.0)\n",
    "        cd.setdefault(\"flow_weighting_scheme\", \"none\")\n",
    "        cd.setdefault(\"flow_logit_mean\", 0.0)\n",
    "        cd.setdefault(\"flow_logit_std\", 1.0)\n",
    "        cd.setdefault(\"flow_mode_scale\", 1.29)\n",
    "        \n",
    "        # cd.setdefault(\"enable_slicing\", False)\n",
    "        # cd.setdefault(\"enable_tiling\", False)\n",
    "        \n",
    "        args = argparse.Namespace(**cd)\n",
    "        args.lr = float(args.lr)\n",
    "        args.epsilon = float(args.epsilon)\n",
    "        args.weight_decay = float(args.weight_decay)\n",
    "        args.target_modules = args.target_modules.split(\" \")\n",
    "\n",
    "        self.args = args\n",
    "        self.state = State()\n",
    "\n",
    "        # Tokenizers\n",
    "        self.tokenizer = None\n",
    "        # self.tokenizer_2 = None\n",
    "        # self.tokenizer_3 = None\n",
    "        # Text encoders\n",
    "        self.text_encoder = None\n",
    "        # self.text_encoder_2 = None\n",
    "        # self.text_encoder_3 = None\n",
    "\n",
    "        # Denoisers\n",
    "        self.transformer = None\n",
    "        self.unet = None\n",
    "\n",
    "        # Autoencoders\n",
    "        self.vae = None\n",
    "\n",
    "        # Scheduler\n",
    "        self.scheduler = None\n",
    "\n",
    "        self._init_distributed()\n",
    "        self._init_logging()\n",
    "        self._init_directories_and_repositories()\n",
    "\n",
    "        self.state.model_name = self.args.model_name\n",
    "\n",
    "        self.model_config = LTX_VIDEO_T2V_LORA_CONFIG\n",
    "        # self.model_config = get_config_from_model_name(self.args.model_name, self.args.training_type)\n",
    "    \n",
    "    def _init_distributed(self):\n",
    "        logging_dir = Path(self.args.output_dir, self.args.logging_dir)\n",
    "        project_config = ProjectConfiguration(project_dir=self.args.output_dir, logging_dir=logging_dir)\n",
    "        ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "        init_process_group_kwargs = InitProcessGroupKwargs(\n",
    "            backend=\"nccl\", timeout=timedelta(seconds=self.args.nccl_timeout)\n",
    "        )\n",
    "        mixed_precision = \"no\" if torch.backends.mps.is_available() else self.args.mixed_precision\n",
    "        report_to = None if self.args.report_to.lower() == \"none\" else self.args.report_to\n",
    "\n",
    "        accelerator = Accelerator(\n",
    "            project_config=project_config,\n",
    "            gradient_accumulation_steps=self.args.gradient_accumulation_steps,\n",
    "            mixed_precision=mixed_precision,\n",
    "            log_with=report_to,\n",
    "            kwargs_handlers=[ddp_kwargs, init_process_group_kwargs],\n",
    "        )\n",
    "\n",
    "        # Disable AMP for MPS.\n",
    "        if torch.backends.mps.is_available():\n",
    "            accelerator.native_amp = False\n",
    "\n",
    "        self.state.accelerator = accelerator\n",
    "\n",
    "        if self.args.seed is not None:\n",
    "            self.state.seed = self.args.seed\n",
    "            set_seed(self.args.seed)\n",
    "\n",
    "        weight_dtype = torch.float32\n",
    "        if self.state.accelerator.mixed_precision == \"fp16\":\n",
    "            weight_dtype = torch.float16\n",
    "        elif self.state.accelerator.mixed_precision == \"bf16\":\n",
    "            weight_dtype = torch.bfloat16\n",
    "            \n",
    "        self.state.weight_dtype = weight_dtype\n",
    "        \n",
    "    def _init_logging(self):\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "            datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "            level=LOG_LEVEL,\n",
    "        )\n",
    "        if self.state.accelerator.is_local_main_process:\n",
    "            transformers.utils.logging.set_verbosity_warning()\n",
    "            diffusers.utils.logging.set_verbosity_info()\n",
    "        else:\n",
    "            transformers.utils.logging.set_verbosity_error()\n",
    "            diffusers.utils.logging.set_verbosity_error()\n",
    "\n",
    "        logger.info(\"Initialized Trainer\")\n",
    "        logger.info(self.state.accelerator.state, main_process_only=False)\n",
    "        \n",
    "    def _init_directories_and_repositories(self):\n",
    "        if self.state.accelerator.is_main_process:\n",
    "            self.args.output_dir = Path(self.args.output_dir)\n",
    "            self.args.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            self.state.output_dir = self.args.output_dir\n",
    "    \n",
    "    def prepare_dataset(self) -> None:\n",
    "        logger.info(\"Initializing dataset and dataloader\")\n",
    "\n",
    "        self.dataset = PrecomputedDataset(\n",
    "            data_dir=self.args.data_root,\n",
    "            width=768,\n",
    "            height=512,\n",
    "            num_frames=49, \n",
    "        )\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.args.batch_size,\n",
    "            # sampler=BucketSampler(self.dataset, batch_size=self.args.batch_size, shuffle=True),\n",
    "            # collate_fn=self.model_config.get(\"collate_fn\"),\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "            pin_memory=self.args.pin_memory,\n",
    "        )\n",
    "    def prepare_models(self):\n",
    "        logger.info(\"Initializing models\")\n",
    "        device = self.state.accelerator.device\n",
    "        dtype = self.state.weight_dtype\n",
    "        \n",
    "        # >> we use precomputation so text encoder is not needed\n",
    "        # cond_models = load_condition_models()\n",
    "        # tokenizer, text_encoder = cond_models[\"tokenizer\"], cond_models[\"text_encoder\"]\n",
    "        # self.text_encoder = text_encoder.to(device, dtype=dtype)\n",
    "        \n",
    "        # self.vae = load_latent_models()[\"vae\"].to(device, dtype=dtype)\n",
    "\n",
    "        # if self.vae is not None:\n",
    "        #     if self.args.enable_slicing:\n",
    "        #         self.vae.enable_slicing()\n",
    "        #     if self.args.enable_tiling:\n",
    "        #         self.vae.enable_tiling()\n",
    "        diff_models = load_diffusion_models()\n",
    "        self.transformer = diff_models[\"transformer\"].to(device, dtype=dtype)\n",
    "        self.scheduler = diff_models[\"scheduler\"]\n",
    "        self.transformer_config = self.transformer.config if self.transformer is not None else None\n",
    "\n",
    "    def prepare_trainable_parameters(self):\n",
    "        logger.info(\"Initializing trainable parameters\")\n",
    "        \n",
    "        if self.args.train_type == \"lora\":\n",
    "            components_to_disable_grads = [ self.transformer ] # self.vae \n",
    "        else:\n",
    "            components_to_disable_grads = []\n",
    "            \n",
    "        for component in components_to_disable_grads:\n",
    "            if component is not None:\n",
    "                component.requires_grad_(False)\n",
    "\n",
    "        if torch.backends.mps.is_available() and self.state.weight_dtype == torch.bfloat16:\n",
    "            # due to pytorch#99272, MPS does not yet support bfloat16.\n",
    "            raise ValueError(\n",
    "                \"Mixed precision training with bfloat16 is not supported on MPS. Please use fp16 (recommended) or fp32 instead.\"\n",
    "            )\n",
    "\n",
    "        if self.args.gradient_checkpointing:\n",
    "            self.transformer.enable_gradient_checkpointing()\n",
    "\n",
    "        if self.args.train_type == \"lora\":\n",
    "            transformer_lora_config = LoraConfig(\n",
    "                r=self.args.rank,\n",
    "                lora_alpha=self.args.lora_alpha,\n",
    "                init_lora_weights=True,\n",
    "                target_modules=self.args.target_modules,\n",
    "            )\n",
    "            self.transformer.add_adapter(transformer_lora_config)\n",
    "\n",
    "        # TODO: refactor\n",
    "        # create custom saving & loading hooks so that `accelerator.save_state(...)` serializes in a nice format\n",
    "        def save_model_hook(models, weights, output_dir):\n",
    "            if self.state.accelerator.is_main_process:\n",
    "                transformer_lora_layers_to_save = None\n",
    "\n",
    "                for model in models:\n",
    "                    if isinstance(\n",
    "                        unwrap_model(self.state.accelerator, model),\n",
    "                        type(unwrap_model(self.state.accelerator, self.transformer)),\n",
    "                    ):\n",
    "                        model = unwrap_model(self.state.accelerator, model)\n",
    "                        transformer_lora_layers_to_save = get_peft_model_state_dict(model)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected save model: {model.__class__}\")\n",
    "\n",
    "                    # make sure to pop weight so that corresponding model is not saved again\n",
    "                    if weights:\n",
    "                        weights.pop()\n",
    "\n",
    "                self.model_config[\"pipeline_cls\"].save_lora_weights(\n",
    "                    output_dir,\n",
    "                    transformer_lora_layers=transformer_lora_layers_to_save,\n",
    "                )\n",
    "\n",
    "        def load_model_hook(models, input_dir):\n",
    "            transformer_ = self.model_config[\"pipeline_cls\"].from_pretrained(\n",
    "                self.args.pretrained_model_name_or_path, subfolder=\"transformer\"\n",
    "            )\n",
    "            transformer_.add_adapter(transformer_lora_config)\n",
    "\n",
    "            lora_state_dict = self.model_config[\"pipeline_cls\"].lora_state_dict(input_dir)\n",
    "\n",
    "            transformer_state_dict = {\n",
    "                f'{k.replace(\"transformer.\", \"\")}': v\n",
    "                for k, v in lora_state_dict.items()\n",
    "                if k.startswith(\"transformer.\")\n",
    "            }\n",
    "            incompatible_keys = set_peft_model_state_dict(transformer_, transformer_state_dict, adapter_name=\"default\")\n",
    "            if incompatible_keys is not None:\n",
    "                # check only for unexpected keys\n",
    "                unexpected_keys = getattr(incompatible_keys, \"unexpected_keys\", None)\n",
    "                if unexpected_keys:\n",
    "                    logger.warning(\n",
    "                        f\"Loading adapter weights from state_dict led to unexpected keys not found in the model: \"\n",
    "                        f\" {unexpected_keys}. \"\n",
    "                    )\n",
    "\n",
    "            # Make sure the trainable params are in float32. This is again needed since the base models\n",
    "            # are in `weight_dtype`. More details:\n",
    "            # https://github.com/huggingface/diffusers/pull/6514#discussion_r1449796804\n",
    "            if self.args.mixed_precision == \"fp16\":\n",
    "                # only upcast trainable parameters (LoRA) into fp32\n",
    "                cast_training_params([transformer_])\n",
    "\n",
    "        self.state.accelerator.register_save_state_pre_hook(save_model_hook)\n",
    "        self.state.accelerator.register_load_state_pre_hook(load_model_hook)\n",
    "\n",
    "        # Enable TF32 for faster training on Ampere GPUs: https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\n",
    "        if self.args.allow_tf32 and torch.cuda.is_available():\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            \n",
    "    def prepare_optimizer(self):\n",
    "        logger.info(\"Initializing optimizer and lr scheduler\")\n",
    "\n",
    "        self.state.train_epochs = self.args.train_epochs\n",
    "        self.state.train_steps = self.args.train_steps\n",
    "\n",
    "        # Make sure the trainable params are in float32\n",
    "        if self.args.mixed_precision == \"fp16\":\n",
    "            # only upcast trainable parameters (LoRA) into fp32\n",
    "            cast_training_params([self.transformer], dtype=torch.float32)\n",
    "\n",
    "        self.state.learning_rate = self.args.lr\n",
    "        if self.args.scale_lr:\n",
    "            self.state.learning_rate = (\n",
    "                self.state.learning_rate\n",
    "                * self.args.gradient_accumulation_steps\n",
    "                * self.args.batch_size\n",
    "                * self.state.accelerator.num_processes\n",
    "            )\n",
    "\n",
    "        transformer_lora_parameters = list(filter(lambda p: p.requires_grad, self.transformer.parameters()))\n",
    "        transformer_parameters_with_lr = {\n",
    "            \"params\": transformer_lora_parameters,\n",
    "            \"lr\": self.state.learning_rate,\n",
    "        }\n",
    "        params_to_optimize = [transformer_parameters_with_lr]\n",
    "        self.state.num_trainable_parameters = sum(p.numel() for p in transformer_lora_parameters)\n",
    "\n",
    "        # TODO(aryan): add deepspeed support\n",
    "        optimizer = get_optimizer(\n",
    "            params_to_optimize=params_to_optimize,\n",
    "            optimizer_name=self.args.optimizer,\n",
    "            learning_rate=self.args.lr,\n",
    "            beta1=self.args.beta1,\n",
    "            beta2=self.args.beta2,\n",
    "            beta3=self.args.beta3,\n",
    "            epsilon=self.args.epsilon,\n",
    "            weight_decay=self.args.weight_decay,\n",
    "            use_8bit = self.args.optimizer_8bit,\n",
    "            use_torchao = self.args.optimizer_torchao,\n",
    "        )\n",
    "\n",
    "        num_update_steps_per_epoch = math.ceil(len(self.dataloader) / self.args.gradient_accumulation_steps)\n",
    "        if self.state.train_steps is None:\n",
    "            self.state.train_steps = self.state.train_epochs * num_update_steps_per_epoch\n",
    "            self.state.overwrote_max_train_steps = True\n",
    "\n",
    "        lr_scheduler = get_scheduler(\n",
    "            name=self.args.lr_scheduler,\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=self.args.lr_warmup_steps * self.state.accelerator.num_processes,\n",
    "            num_training_steps=self.state.train_steps * self.state.accelerator.num_processes,\n",
    "            num_cycles=self.args.lr_num_cycles,\n",
    "            power=self.args.lr_power,\n",
    "        )\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        \n",
    "    def prepare_for_training(self):\n",
    "        self.transformer, self.optimizer, self.dataloader, self.lr_scheduler = self.state.accelerator.prepare(\n",
    "            self.transformer, self.optimizer, self.dataloader, self.lr_scheduler\n",
    "        )\n",
    "\n",
    "        # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n",
    "        # num_update_steps_per_epoch = math.ceil(len(self.dataloader) / self.args.gradient_accumulation_steps)\n",
    "        # if self.state.overwrote_max_train_steps:\n",
    "        #     self.state.train_steps = self.state.train_epochs * num_update_steps_per_epoch\n",
    "        # Afterwards we recalculate our number of training epochs\n",
    "        # self.state.train_epochs = math.ceil(self.state.train_steps / num_update_steps_per_epoch)\n",
    "        \n",
    "    def prepare_trackers(self):\n",
    "        logger.info(\"Initializing trackers\")\n",
    "\n",
    "        tracker_name = self.args.tracker_name or \"ltx_train\"\n",
    "        self.state.accelerator.init_trackers(tracker_name, config=self.args.__dict__)\n",
    "        \n",
    "    def train(self):\n",
    "        logger.info(\"Starting training\")\n",
    "\n",
    "        memory_statistics = get_memory_statistics()\n",
    "        logger.info(f\"Memory before training start: {json.dumps(memory_statistics, indent=4)}\")\n",
    "\n",
    "        self.state.train_batch_size = (\n",
    "            self.args.batch_size * self.state.accelerator.num_processes * self.args.gradient_accumulation_steps\n",
    "        )\n",
    "        info = {\n",
    "            \"trainable parameters\": self.state.num_trainable_parameters,\n",
    "            \"total samples\": len(self.dataset),\n",
    "            \"train epochs\": self.state.train_epochs,\n",
    "            \"train steps\": self.state.train_steps,\n",
    "            \"batches per device\": self.args.batch_size,\n",
    "            \"total batches observed per epoch\": len(self.dataloader),\n",
    "            \"train batch size\": self.state.train_batch_size,\n",
    "            \"gradient accumulation steps\": self.args.gradient_accumulation_steps,\n",
    "        }\n",
    "        logger.info(f\"Training configuration: {json.dumps(info, indent=4)}\")\n",
    "        \n",
    "        global_step = 0\n",
    "        first_epoch = 0\n",
    "        initial_global_step = 0\n",
    "        progress_bar = tqdm(\n",
    "            range(0, self.state.train_steps),\n",
    "            initial=initial_global_step,\n",
    "            desc=\"Training steps\",\n",
    "            disable=not self.state.accelerator.is_local_main_process,\n",
    "        )\n",
    "\n",
    "        accelerator = self.state.accelerator\n",
    "        weight_dtype = self.state.weight_dtype\n",
    "        scheduler_sigmas = self.scheduler.sigmas.clone().to(device=accelerator.device, dtype=weight_dtype)\n",
    "        generator = torch.Generator(device=accelerator.device)\n",
    "        if self.args.seed is not None:\n",
    "            generator = generator.manual_seed(self.args.seed)\n",
    "        self.state.generator = generator\n",
    "\n",
    "        for epoch in range(first_epoch, self.state.train_epochs):\n",
    "            logger.debug(f\"Starting epoch ({epoch + 1}/{self.state.train_epochs})\")\n",
    "\n",
    "            self.transformer.train()\n",
    "\n",
    "            for step, batch in enumerate(self.dataloader):\n",
    "                logger.debug(f\"Starting step {step + 1}\")\n",
    "                logs = {}\n",
    "\n",
    "                with accelerator.accumulate([ self.transformer ]):\n",
    "                    latents, prompt_embeds, prompt_attention_mask, caption, meta_info = batch\n",
    "                    \n",
    "                    # latent_conditions = batch[\"latent_conditions\"]\n",
    "                    # text_conditions = batch[\"text_conditions\"]\n",
    "                    # latent_conditions[\"latents\"] = DiagonalGaussianDistribution(\n",
    "                    #     latent_conditions[\"latents\"]\n",
    "                    # ).sample(generator)\n",
    "                    # print(\"--\", latents.shape)\n",
    "                    # latents = DiagonalGaussianDistribution(latents).sample(generator)\n",
    "                    # print(\"Diagonal\", latents.shape)\n",
    "                    \n",
    "                    # if \"post_latent_preparation\" in self.model_config.keys():\n",
    "                    #     latent_conditions = self.model_config[\"post_latent_preparation\"](**latent_conditions)\n",
    "                        \n",
    "                    # align_device_and_dtype(latents, accelerator.device, weight_dtype)\n",
    "                    # align_device_and_dtype(text_conditions, accelerator.device, weight_dtype)\n",
    "                    latents = latents.to(accelerator.device, dtype=weight_dtype).contiguous()\n",
    "                    prompt_embeds = prompt_embeds.to(accelerator.device, dtype=weight_dtype).contiguous()\n",
    "                    prompt_attention_mask = prompt_attention_mask.to(accelerator.device, dtype=weight_dtype)\n",
    "                    batch_size = latents.shape[0]\n",
    "\n",
    "                    # latent_conditions = make_contiguous(latent_conditions)\n",
    "                    # text_conditions = make_contiguous(text_conditions)\n",
    "                    \n",
    "\n",
    "                    if self.args.caption_dropout_technique == \"zero\":\n",
    "                        if random.random() < self.args.caption_dropout_p:\n",
    "                            # text_conditions[\"prompt_embeds\"].fill_(0)\n",
    "                            prompt_embeds.fill_(0)\n",
    "                            prompt_attention_mask.fill_(False)\n",
    "\n",
    "                            # if \"pooled_prompt_embeds\" in text_conditions:\n",
    "                            #     text_conditions[\"pooled_prompt_embeds\"].fill_(0)\n",
    "\n",
    "                    # These weighting schemes use a uniform timestep sampling and instead post-weight the loss\n",
    "                    weights = compute_density_for_timestep_sampling(\n",
    "                        weighting_scheme=self.args.flow_weighting_scheme,\n",
    "                        batch_size=batch_size,\n",
    "                        logit_mean=self.args.flow_logit_mean,\n",
    "                        logit_std=self.args.flow_logit_std,\n",
    "                        mode_scale=self.args.flow_mode_scale,\n",
    "                    )\n",
    "                    indices = (weights * self.scheduler.config.num_train_timesteps).long()\n",
    "                    sigmas = scheduler_sigmas[indices]\n",
    "                    timesteps = (sigmas * 1000.0).long()\n",
    "                    print(\"sigmas\", sigmas.shape, \"weights\", weights, \"timesteps\", timesteps.shape)\n",
    "                    \n",
    "                    noise = torch.randn(\n",
    "                        latents.shape,\n",
    "                        generator=generator,\n",
    "                        device=accelerator.device,\n",
    "                        dtype=weight_dtype,\n",
    "                    )\n",
    "                    ss= sigmas.reshape(-1, 1, 1).repeat(1, 1, latents.size(-1))\n",
    "                    print(\"ss\", ss.shape, latents.shape)\n",
    "                    noisy_latents = (1.0 - ss) * latents + ss * noise\n",
    "\n",
    "                    # These weighting schemes use a uniform timestep sampling and instead post-weight the loss\n",
    "                    weights = compute_loss_weighting_for_sd3(\n",
    "                        weighting_scheme=self.args.flow_weighting_scheme, sigmas=sigmas\n",
    "                    ).reshape(-1, 1, 1).repeat(1, 1, latents.size(-1))\n",
    "                    print(\"weights\", weights)\n",
    "                    pred = self.model_config[\"forward_pass\"](\n",
    "                        transformer=self.transformer, \n",
    "                        timesteps=timesteps, \n",
    "                        latents=latents,\n",
    "                        noisy_latents=noisy_latents,\n",
    "                        prompt_embeds=prompt_embeds, \n",
    "                        prompt_attention_mask=prompt_attention_mask,\n",
    "                        num_frames=meta_info[\"num_frames\"][0],\n",
    "                        height=meta_info[\"height\"][0],\n",
    "                        width=meta_info[\"width\"][0],\n",
    "                    )\n",
    "                    target = noise - latents\n",
    "\n",
    "                    loss = weights.float() * (pred[\"latents\"].float() - target.float()).pow(2)\n",
    "                    # Average loss across channel dimension\n",
    "                    loss = loss.mean(list(range(1, loss.ndim)))\n",
    "                    # Average loss across batch dimension\n",
    "                    loss = loss.mean()\n",
    "                    accelerator.backward(loss)\n",
    "\n",
    "                    if accelerator.sync_gradients and accelerator.distributed_type != DistributedType.DEEPSPEED:\n",
    "                        grad_norm = accelerator.clip_grad_norm_(self.transformer.parameters(), self.args.max_grad_norm)\n",
    "                        logs[\"grad_norm\"] = grad_norm\n",
    "\n",
    "                    self.optimizer.step()\n",
    "                    self.lr_scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                # Checks if the accelerator has performed an optimization step behind the scenes\n",
    "                if accelerator.sync_gradients:\n",
    "                    progress_bar.update(1)\n",
    "                    global_step += 1\n",
    "\n",
    "                    # Checkpointing\n",
    "                    if accelerator.distributed_type == DistributedType.DEEPSPEED or accelerator.is_main_process:\n",
    "                        if global_step % self.args.checkpointing_steps == 0:\n",
    "                            # before saving state, check if this save would set us over the `checkpointing_limit`\n",
    "                            if self.args.checkpointing_limit is not None:\n",
    "                                checkpoints = find_files(self.args.output_dir, prefix=\"checkpoint\")\n",
    "\n",
    "                                # before we save the new checkpoint, we need to have at_most `checkpoints_total_limit - 1` checkpoints\n",
    "                                if len(checkpoints) >= self.args.checkpointing_limit:\n",
    "                                    num_to_remove = len(checkpoints) - self.args.checkpointing_limit + 1\n",
    "                                    checkpoints_to_remove = checkpoints[0:num_to_remove]\n",
    "                                    delete_files(checkpoints_to_remove)\n",
    "\n",
    "                            logger.info(f\"Checkpointing at step {global_step}\")\n",
    "                            save_path = os.path.join(self.args.output_dir, f\"checkpoint-{global_step}\")\n",
    "                            accelerator.save_state(save_path)\n",
    "                            logger.info(f\"Saved state to {save_path}\")\n",
    "\n",
    "                # Maybe run validation\n",
    "                should_run_validation = (\n",
    "                    self.args.validation_steps is not None\n",
    "                    and global_step % self.args.validation_steps == 0\n",
    "                )\n",
    "                if should_run_validation:\n",
    "                    self.validate(global_step)\n",
    "\n",
    "                logs = {\"loss\": loss.detach().item(), \"lr\": self.lr_scheduler.get_last_lr()[0]}\n",
    "                progress_bar.set_postfix(logs)\n",
    "                accelerator.log(logs, step=global_step)\n",
    "\n",
    "                if global_step >= self.state.train_steps:\n",
    "                    break\n",
    "\n",
    "            memory_statistics = get_memory_statistics()\n",
    "            logger.info(f\"Memory after epoch {epoch + 1}: {json.dumps(memory_statistics, indent=4)}\")\n",
    "\n",
    "            # Maybe run validation\n",
    "            # should_run_validation = (\n",
    "            #     self.args.validation_every_n_epochs is not None\n",
    "            #     and (epoch + 1) % self.args.validation_every_n_epochs == 0\n",
    "            # )\n",
    "            # if should_run_validation:\n",
    "            #     self.validate(global_step)\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        if accelerator.is_main_process:\n",
    "            self.transformer = unwrap_model(accelerator, self.transformer)\n",
    "            dtype = (\n",
    "                torch.float16\n",
    "                if self.args.mixed_precision == \"fp16\"\n",
    "                else torch.bfloat16\n",
    "                if self.args.mixed_precision == \"bf16\"\n",
    "                else torch.float32\n",
    "            )\n",
    "            self.transformer = self.transformer.to(dtype)\n",
    "            transformer_lora_layers = get_peft_model_state_dict(self.transformer)\n",
    "\n",
    "            self.model_config[\"pipeline_cls\"].save_lora_weights(\n",
    "                save_directory=self.args.output_dir,\n",
    "                transformer_lora_layers=transformer_lora_layers,\n",
    "            )\n",
    "\n",
    "        del self.transformer, self.scheduler\n",
    "        free_memory()\n",
    "        memory_statistics = get_memory_statistics()\n",
    "        logger.info(f\"Memory after training end: {json.dumps(memory_statistics, indent=4)}\")\n",
    "\n",
    "        accelerator.end_training()\n",
    "    \n",
    "    def evaluate(self):\n",
    "        logger.info(\"Starting validation\")\n",
    "        pass\n",
    "        \n",
    "# trainer = Trainer(\"ltx_training/configs/ltx.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c696be-abbc-4fd7-86ba-dfc2ec9b0e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafc257-d899-4a54-99ff-d16aa0a8644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\"configs/ltx.yaml\")\n",
    "\n",
    "trainer.prepare_dataset()\n",
    "trainer.prepare_models()\n",
    "trainer.prepare_trainable_parameters()\n",
    "trainer.prepare_optimizer()\n",
    "trainer.prepare_for_training()\n",
    "trainer.prepare_trackers()\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f26b876-b222-4f83-9cfd-35d7a1f6c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4946) tensor(0.1420)\n",
      "tensor(0.6169) tensor(0.2430)\n"
     ]
    }
   ],
   "source": [
    "aa = torch.sigmoid(torch.randn(10, 1, 1))\n",
    "bb = torch.rand(10, 1, 1)\n",
    "print(aa.mean(), aa.std())\n",
    "print(bb.mean(), bb.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42569fdd-22b3-4554-89d9-5a929cda5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eisneim/.conda/envs/_learn/lib/python3.10/logging/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(logging.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c89d01de-4b9a-4bb0-9bff-eb02f359ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = next(iter(trainer.dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21ba9434-36f9-4068-94a6-f70a47a32e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6e-05"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4175a93a-08ee-40a1-9eaf-b5e84f82471d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3e-05"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7800e742-b970-47fd-81b3-d0783ff5b33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d2904b0-b48e-419f-8316-437f057d3da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = \"343\"\n",
    "isinstance(aa, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ddbc11f-7e9a-486d-b9d4-05bfff083b9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'setdefault'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetdefault\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'setdefault'"
     ]
    }
   ],
   "source": [
    "aa.setdefault(\"c\", 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a3a084-69a3-4f4c-86dd-33aa6d25c474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(a=1, b=1e-05, c=0.001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab = argparse.Namespace(**aa)\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b97af5-6049-496e-abb4-6ec761af4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216535/1469043893.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'latents': tensor([[[ 0.4414, -0.3730, -0.3945,  ..., -0.5742,  0.0530, -0.2520],\n",
       "          [ 0.4941, -0.3555,  0.2021,  ..., -0.8242,  0.3711, -0.5742],\n",
       "          [ 0.4316, -0.4570, -0.0957,  ..., -1.3047,  0.0991, -0.1445],\n",
       "          ...,\n",
       "          [-0.7148, -0.4668, -0.1191,  ...,  0.2891, -2.0312, -0.0093],\n",
       "          [-0.0302, -0.6680, -0.7344,  ..., -0.0815, -1.8281, -0.2090],\n",
       "          [ 1.0469, -0.8047, -0.5273,  ..., -0.6992, -1.9766, -0.1592]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'embedds': tensor([[[ 0.1602, -0.0073, -0.1445,  ..., -0.1543, -0.1162, -0.0337],\n",
       "          [ 0.1260,  0.0156,  0.1270,  ..., -0.1709, -0.0042, -0.1816],\n",
       "          [-0.0280,  0.0708,  0.1074,  ...,  0.0030,  0.0339, -0.0942],\n",
       "          ...,\n",
       "          [ 0.0771, -0.0098, -0.0084,  ..., -0.1357, -0.0674, -0.0043],\n",
       "          [ 0.0388, -0.0135,  0.0410,  ..., -0.1011, -0.2236, -0.0259],\n",
       "          [ 0.0101,  0.1157, -0.1177,  ..., -0.0334, -0.0569,  0.0130]]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'masks': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.]], dtype=torch.bfloat16),\n",
       " 'captions': ['freeze time, camera orbit left,  a rugged off-road vehicle, likely designed for challenging terrain, parked at the edge of an elevated platform with expansive views. The surrounding landscape is lush and green, suggesting a hilly or mountainous region near a large body of water that could be a sea or ocean. The sky above is partly cloudy but allows ample sunlight to illuminate the scene.']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"/home/eisneim/www/ml/video_gen/ltx_training/data/ltxv_disney_49x768x512-normed/VID_20230606_101912.pt\"\n",
    "data = torch.load(file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ce3ceef-a268-41d8-b616-092ac5fd6508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.tensor([0.1, 0.2])\n",
    "aa = aa.unsqueeze(dim=1).repeat(1, 4)\n",
    "print(aa, aa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d02054-b8c5-4b45-ae15-fd79d4502628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "576/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c121b09b-bcf0-477c-9032-c8953faa521b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43503c6e-38e0-461d-9002-68d50fb9d153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_learn",
   "language": "python",
   "name": "_learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
